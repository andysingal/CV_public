{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7760846,"sourceType":"datasetVersion","datasetId":4538824}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **SDXL - Base**","metadata":{}},{"cell_type":"code","source":"pip install diffusers invisible_watermark transformers accelerate safetensors","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install xformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from diffusers import StableDiffusionXLPipeline\nimport torch\n\n\npipe = StableDiffusionXLPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\",\n    torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\").to(\"cuda\")\n\n# pipe.enable_xformers_memory_efficient_attention() # For torch < 2.0\n# pipe.unet = torch.compile(pipe.unet, mode=\"max-autotune\", fullgraph=True) # For torch > 2.0\n\n# pipe.enable_model_cpu_offload()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Default - num_inference_steps=50, guidance_scale=5\n\nprompt = '''capture a fine-detailed front profile of a 30 year old women walking at a busy street, \n    street side food stall, photo realistic, f/2.8'''\n\nimage = pipe(prompt=prompt, guidance_scale=15).images[0]\nimage","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **SDXL - Base + Refiner**","metadata":{}},{"cell_type":"code","source":"from diffusers import DiffusionPipeline\nimport torch\n\nbase = DiffusionPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\",\n    use_safetensors=True).to(\"cuda\")\n\nrefiner = DiffusionPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n    text_encoder_2=base.text_encoder_2,\n    vae=base.vae,\n    torch_dtype=torch.float16,\n    use_safetensors=True,\n    variant=\"fp16\",\n).to(\"cuda\")\n\n# base.enable_model_cpu_offload()\n# refiner.enable_model_cpu_offload()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = '''capture a fine-detailed front profile of a 30 year old women walking at a busy street, \n    street side food stall, photo realistic, f/2.8'''\n\nimage = base(\n    prompt=prompt,\n    num_inference_steps=50,\n    denoising_end=0.8,\n    output_type=\"latent\",\n).images\n\nimage = refiner(\n    prompt=prompt,\n    num_inference_steps=50,\n    denoising_start=0.8,\n    image=image,\n).images[0]\nimage","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **SDXL - lcm-LoRA-sdxl**","metadata":{}},{"cell_type":"code","source":"pip install peft","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom diffusers import LCMScheduler, AutoPipelineForText2Image\n\nmodel_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\nadapter_id = \"latent-consistency/lcm-lora-sdxl\"\n\npipe = AutoPipelineForText2Image.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\")\npipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\npipe.to(\"cuda\")\n\npipe.load_lora_weights(adapter_id)\npipe.fuse_lora()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_inference_steps=4, blurry, no creativity, requires facial prompts\n# guidance_scale=0 or guidance_scale between 1.0 and 2.0\n\nprompt = '''a 30 year old women sitting on a wooden and metal chair, fair skin, casual attire, \n    sunglasses, heels, white background, sideby tea table, photoshoot, photo realistic'''\n\nimage = pipe(prompt=prompt, num_inference_steps=4, guidance_scale=1).images[0]\nimage","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n# **SDXL lightning - UNet**","metadata":{}},{"cell_type":"code","source":"# pip install huggingface_hub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom diffusers import StableDiffusionXLPipeline, UNet2DConditionModel, EulerDiscreteScheduler\nfrom huggingface_hub import hf_hub_download\nfrom safetensors.torch import load_file\n\nbase = \"stabilityai/stable-diffusion-xl-base-1.0\"\nrepo = \"ByteDance/SDXL-Lightning\"\nckpt = \"sdxl_lightning_8step_unet.safetensors\" # Use the correct ckpt for your step setting!\n\n# Load model.\nunet = UNet2DConditionModel.from_config(base, subfolder=\"unet\").to(\"cuda\", torch.float16)\nunet.load_state_dict(load_file(hf_hub_download(repo, ckpt), device=\"cuda\"))\npipe = StableDiffusionXLPipeline.from_pretrained(base, unet=unet, torch_dtype=torch.float16, variant=\"fp16\")\npipe.to(\"cuda\")\n\npipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = '''a 30 year old women sitting on a chair in sunlit park, fair skin, sunglasses,\n    photoshoot, ultra-realistic photograph, fine detailed, extreme close up, \n    f/2.8 aperture, 35mm lens'''\n\nimage = pipe(prompt=prompt, num_inference_steps=8, guidance_scale=0.8).images[0]\nimage","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **SDXL lightning - LoRA**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom diffusers import StableDiffusionXLPipeline, EulerDiscreteScheduler\nfrom huggingface_hub import hf_hub_download\n\n\nbase = \"stabilityai/stable-diffusion-xl-base-1.0\"\nrepo = \"ByteDance/SDXL-Lightning\"\nckpt = \"sdxl_lightning_4step_lora.safetensors\" # Use the correct ckpt for your step setting!\n\n# Load model.\npipe = StableDiffusionXLPipeline.from_pretrained(base, torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\npipe.load_lora_weights(hf_hub_download(repo, ckpt))\npipe.fuse_lora()\n\npipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = ''''a 30 year old women sitting on a wooden and metal chair,\n    fair skin, casual attire, sunglasses, heels,\n    white background, sideby wooden table, photoshoot, photo realistic'''\n\nimage = pipe(prompt=prompt, num_inference_steps=4, guidance_scale=0).images[0]\n\nimage","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **playground-v2.5-1024px-aesthetic**","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/diffusers\n# diffusers >= 0.27.0 unofficial and currently in dev","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from diffusers import DiffusionPipeline, EDMDPMSolverMultistepScheduler\nimport torch\n\npipe = DiffusionPipeline.from_pretrained(\n    \"playgroundai/playground-v2.5-1024px-aesthetic\",\n    torch_dtype=torch.float16,\n    variant=\"fp16\",\n).to(\"cuda\")\n\npipe.scheduler = EDMDPMSolverMultistepScheduler()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = '''A high resolution photorealistic fashion photograph of a beautiful model wearing\n    a red backless gown standing under spotlights against a black background. \n    Shot from a low angle perspective with a shallow depth of field.'''\n\nimage = pipe(prompt=prompt, num_inference_steps=50, guidance_scale=3).images[0]\nimage","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Stable Diffusion x4 Upscaler**","metadata":{}},{"cell_type":"code","source":"from diffusers import StableDiffusionUpscalePipeline\nimport torch\n\nupscaler = StableDiffusionUpscalePipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-x4-upscaler\", torch_dtype=torch.float16).to(\"cuda\")\n\n\n# from PIL import Image\n# image = Image.open(\"/kaggle/working/women_earrings.png\").convert('RGB')\n\nprompt = '''a beautiful lady sitting on a wooden and metal chair, fair skin, casual attire, \n    sunglasses, heels, white background, sideby tea table, photoshoot, photo realistic, 4k, f/2.8'''\n\nupscaled_image = upscaler(prompt=prompt, image=image).images[0]\n\nprint(upscaled_image.size)\nupscaled_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **RealESRGAN Upscaler**","metadata":{}},{"cell_type":"code","source":"# Upload the below git repository as dataset to the notebook input\n# https://github.com/ai-forever/Real-ESRGAN","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/real-esrgan-1\")\n\nimport time\nimport torch\nfrom PIL import Image\nimport numpy as np\nfrom RealESRGAN import RealESRGAN\n\n# from PIL import Image\n# image = Image.open(\"/kaggle/input/sample.png\").convert('RGB')\n\nstart = time.time()\n\n# Base x 2 = 1024 x 2 = 2048\nscale = 2\nweight_path = \"weights/RealESRGAN_x2.pth\"\n\n# # Base x 4 = 1024 x 4 = 4096\n# scale = 4\n# weight_path = \"weights/RealESRGAN_x4.pth\"\n\n# # Base x 8 = 1024 x 8 = 8192\n# scale = 8\n# weight_path = \"weights/RealESRGAN_x8.pth\"\n\nmodel = RealESRGAN(torch.device('cuda'), scale=scale)\nmodel.load_weights(weight_path, download=True)\n\nupscaled_image = model.predict(image)\n\nend = time.time()\nprint(upscaled_image.size, \"time=%.2fs\" % (end - start))\nupscaled_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"upscaled_image.save(\"sample_upscaled.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}