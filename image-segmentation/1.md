
In the left half of the preceding diagram, we can see that the image passes through convolution layers,  and that the image size keeps reducing while the number of channels keeps increasing. However, in the right half, we can see that we are upscaling the downscaled image, back to the original height and width but with as many channels as there are classes.

In addition, while upscaling, we are also leveraging information from the corresponding layers in the left half using skip connections so that we can preserve the structure/objects in the original image.

This way, the U-Net architecture learns to preserve the structure (and shapes of objects) of the original image while leveraging the convolution's features to predict the classes that correspond to each pixel.
<img width="660" alt="Screenshot 2024-04-17 at 8 53 27â€¯AM" src="https://github.com/andysingal/CV_public/assets/20493493/9321d8e6-aca8-4b74-ad7d-9b06574ad482">



Resources:
- [Image segmentation detailed overview](https://www.superannotate.com/blog/image-segmentation-for-machine-learning)
- [semantic-segmentation](https://github.com/xitu/gold-miner/blob/db4f91ae0df1f31d3b02dbf21b4137bfb9fda374/TODO1/semantic-segmentation-u-net-part-1.md)
- [15 Interesting Github Repositories for Image Segmentation](https://encord.com/blog/github-repositories-image-segmentation/)
