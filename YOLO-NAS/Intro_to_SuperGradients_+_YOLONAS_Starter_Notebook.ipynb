{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJw-BRX5pzS0"
      },
      "source": [
        "<img src='https://raw.githubusercontent.com/Deci-AI/super-gradients/master/documentation/assets/SG_img/SG%20-%20Horizontal%20Glow%202.png'>\n",
        "\n",
        "## üëãüèΩ What's up! It's [Harpreet](https://twitter.com/DataScienceHarp)\n",
        "\n",
        "I'll be guiding you through this notebook. At any point, if you get stuck or have questions, there are three ways to get in touch:\n",
        "\n",
        "1) Send me an email with your issue: harpreet.sahota@deci.ai\n",
        "\n",
        "2) Hop into the [Deep Learning Daily (powered by Deci) Discord server](https://discord.gg/p9ecgRhDR8), and let me know what your question is.\n",
        "\n",
        "3) [Open an issue on GitHub](https://github.com/Deci-AI/super-gradients/issues/new/choose)\n",
        "\n",
        "\n",
        "Let's get to it...\n",
        "\n",
        "üö® Note: after installation is complete (it make take a few minutes), you'll need to restart the runtime.\n",
        "\n",
        "This is a known [issue](https://github.com/obss/sahi/discussions/781) that is on our roadmap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0SkK3bjMOqH"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install super-gradients==3.2.0\n",
        "!pip install imutils\n",
        "!pip install roboflow\n",
        "!pip install pytube --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYZw6UvePBv5"
      },
      "source": [
        "# ü¶∏üèæ‚Äç‚ôÇÔ∏è SuperGradients\n",
        "\n",
        "SuperGradients is a PyTorch based training library.\n",
        "\n",
        "It provides a uniform interface for the most common computer vision use cases:\n",
        "\n",
        "- Classification\n",
        "\n",
        "- Detection\n",
        "\n",
        "- Segmentation\n",
        "\n",
        "- Pose estimation\n",
        "\n",
        "There are nearly 40 pretrained models in our model zoo. You can see the pretrained models available to you by following [this link](https://github.com/Deci-AI/super-gradients/blob/master/documentation/source/model_zoo.md).\n",
        "\n",
        "This notebook will focus on using SuperGradients with YOLO-NAS. If you're interested in seeing how SG is used for image classification, you can check out [this templated notebook](https://colab.research.google.com/drive/1JYyEnEh2VdmKLxd7idUfBt6vLGOZxGIp?usp=sharing) that will make it easy to get started."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qvb96TvUqRX"
      },
      "source": [
        "# ü´£ Sneak peek: Inference with YOLONAS\n",
        "\n",
        "Before jumping into the section on fine-tuning, I wanted to show you the power of YOLONAS out of the box.\n",
        "\n",
        "Start by instantiating a pretrained model. YOLONAS comes in three flavors: `yolo_nas_s`, `yolo_nas_m`, and `yolo_nas_l`.\n",
        "\n",
        "You'll use `yolo_nas_l` throughout this notebook. Because you should always go big, or go home.\n",
        "\n",
        "It's a good life philosophy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFn40GJSXCRJ"
      },
      "outputs": [],
      "source": [
        "from super_gradients.training import models\n",
        "\n",
        "yolo_nas_l = models.get(\"yolo_nas_l\", pretrained_weights=\"coco\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can run the following cell if you're interested in the architecture:"
      ],
      "metadata": {
        "id": "Ee2c-F_uB_IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "summary(model=yolo_nas_l,\n",
        "        input_size=(16, 3, 640, 640),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "id": "uw-3BugfB_va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5LCipgzXXHN"
      },
      "source": [
        "## üñºÔ∏è Inference on an image\n",
        "\n",
        "Once the model has been instantiated all you have to do is call the `predict` method.\n",
        "\n",
        "This method operates on:\n",
        "* PIL Image\n",
        "* Numpy Image\n",
        "* A path to image file\n",
        "* A path to video file\n",
        "* A path to folder with images\n",
        "* URL (Image only)\n",
        "\n",
        "Allowing you to perform inference with ease.\n",
        "\n",
        "Note predict also has an argument called `conf`, which is the threshold for a detection. You change this value as you like, for example `model.predict(\"path/to/asset\",conf=0.25)`\n",
        "\n",
        "Let's perform inference on the following image:\n",
        "\n",
        "<img src='https://previews.123rf.com/images/freeograph/freeograph2011/freeograph201100150/158301822-group-of-friends-gathering-around-table-at-home.jpg'>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqXzphK6XXTF"
      },
      "outputs": [],
      "source": [
        "url = \"https://previews.123rf.com/images/freeograph/freeograph2011/freeograph201100150/158301822-group-of-friends-gathering-around-table-at-home.jpg\"\n",
        "yolo_nas_l.predict(url, conf=0.25).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J64UkzV9XXb7"
      },
      "source": [
        "### ü§∑üèΩ‚Äç‚ôÇÔ∏è What's happening \"under the hood\"\n",
        "\n",
        "1. Input image gets through the preprocessing pipeline, which includes image resizing, normalization and permute operation to convert input RGB image to torch tensor.\n",
        "2. Model inference\n",
        "3. Postprocessing of the detection results (Non-maximum suppression, resizing bounding boxes to the size of original image)\n",
        "4. Visualization of the results (Rendering of bounding boxes on top of the image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukjpGtS8XpgU"
      },
      "source": [
        "# üé• Inference on video\n",
        "\n",
        "The following code will display and download stock footage video from YouTube.\n",
        "\n",
        "[Here's a link](https://www.youtube.com/watch?v=4poqZjNTZjI&list=PLcKa-34z76PvI5KvI5S2JGj0RcBVuz3jg) to a playlist that has a lot of stock video clips which are 2mins in length or less.\n",
        "\n",
        "### üîéü§© Find a video you like and use YOLONAS to perform some inference on it!\n",
        "\n",
        "All you have to do is get the `video_id`, and replace the line `video_id = 'aE8I7bDf62M' ` in the cell below with your chosen video's id.\n",
        "\n",
        "The `video_id` is everything that comes after `https://www.youtube.com/watch?v=`. For the video below, the full url was `https://www.youtube.com/watch?v=aE8I7bDf62M`, and thus the video id is `aE8I7bDf62M`.\n",
        "\n",
        "After you've found a video and performed inference, don't forget to share it on Twitter or LinkedIn.\n",
        "\n",
        "üè∑Ô∏è And tag me in it so I don't miss it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncham2zeUq1r"
      },
      "outputs": [],
      "source": [
        "# Import the YouTubeVideo class from IPython.display\n",
        "from IPython.display import YouTubeVideo\n",
        "\n",
        "# Define the YouTube video ID\n",
        "video_id = 'aE8I7bDf62M'  # Replace YOUR_VIDEO_ID with the actual video ID\n",
        "\n",
        "# Create a YouTubeVideo object with the specified video ID\n",
        "video = YouTubeVideo(video_id)\n",
        "\n",
        "# Display the video\n",
        "display(video)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJyRbkyjUq9-"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Define the URL of the YouTube video\n",
        "video_url = f'https://www.youtube.com/watch?v={video_id}'\n",
        "\n",
        "# Download the video in mp4 format\n",
        "!pip install -U \"git+https://github.com/ytdl-org/youtube-dl.git\"\n",
        "!python -m youtube_dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4' \"$video_url\"\n",
        "\n",
        "# Print a success message\n",
        "print('Video downloaded successfully')\n",
        "\n",
        "input_video_path = f\"/content/EXTREME SPORTS X DIVERSE-{video_id}.mp4\"\n",
        "output_video_path = \"detections.mp4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay5T_iincCsu"
      },
      "source": [
        "### üìΩÔ∏è Now, you'll peform inference on the video\n",
        "\n",
        "Note, Google Colab is notorious for making it hard to display videos.\n",
        "\n",
        "üëÄ Look to the left of the screen for the folder icon, it looks something like this: üñø.\n",
        "\n",
        "Click on that, and you'll see a file called `detections.mp4`.\n",
        "\n",
        "Double click on that to download.\n",
        "\n",
        "Google Colab is also notorious for taking a long time to download. You can continue on with the rest of the notebook while you wait.\n",
        "\n",
        "If you have a work around for this, let me know!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "0APhsWWEk8Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZPkh3JpUrEf"
      },
      "outputs": [],
      "source": [
        "yolo_nas_l.to(device).predict(input_video_path).save(output_video_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2WrTYvCXpt_"
      },
      "source": [
        "### üíª Inference via webcam\n",
        "\n",
        "Check [the documentation](https://github.com/Deci-AI/super-gradients/blob/505f646728249b9b35ea9060f34936f4e88234fd/src/super_gradients/examples/predict/detection_predict_streaming.py) for inference via webcam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93O99TjcoANx"
      },
      "source": [
        "# ü™° Fine-tuning YOLONAS on custom dataset\n",
        "\n",
        "## üèãüèΩ The trainer\n",
        "\n",
        "The first thing you need to define in SuperGradients is the Trainer.\n",
        "\n",
        "The trainer is in charge of training, evaluation, saving checkpoints, etc. If you're interested in seeing the source code for the trainer, you can do so [here](https://github.com/Deci-AI/super-gradients/blob/master/src/super_gradients/training/sg_trainer/sg_trainer.py).\n",
        "\n",
        "### ‚úåüèº There's two important arguments to the trainer:\n",
        "\n",
        "1) `ckpt_root_dir` - this is the directory where results from all your experiments will be saved\n",
        "\n",
        "2)`experiment_name` - all checkpoints, logs, and tensorboards will be saved in a directory with the name you specify here.\n",
        "\n",
        "SuperGradients supports **Data Parallel** and **Distributed Data Parallel**.\n",
        "\n",
        "That's outside of the scope for this introduction to SuperGradients. But, if you're fortunate enough to have multiple GPUs at your disposal or want learn more you can do so [here](https://github.com/Deci-AI/super-gradients/blob/0fe46cd39572db34eb83d68e343fed97b8886fe9/documentation/source/device.md#3-dp---data-parallel).\n",
        "\n",
        "In the code below, you'll instantiate the trainer with just a single GPU (since that's what Google Colab provides)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMtzYc_CoAX3"
      },
      "outputs": [],
      "source": [
        "from super_gradients.training import Trainer\n",
        "\n",
        "CHECKPOINT_DIR = 'checkpoints'\n",
        "trainer = Trainer(experiment_name='my_first_yolonas_run', ckpt_root_dir=CHECKPOINT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQjCqyL9vCnQ"
      },
      "source": [
        "# üíæ Datasets and DataLoaders\n",
        "\n",
        "Before you start, you need to create a Roboflow [account and get your API key](https://app.roboflow.com/login). If you're not sure how to find your API key, [here's how](https://www.loom.com/share/05277274e8d542efaf9bc3f33c1396d3?sid=3a41d4c5-c0c7-4712-bf4b-6a8c7ba51947).\n",
        "\n",
        "SuperGradients is fully compatible with PyTorch Datasets and Dataloaders, so you can use your dataloaders as is.\n",
        "\n",
        "There are several well-known datasets for object detection, for example:\n",
        "\n",
        "- COCO\n",
        "- Pascal\n",
        "- YOLODarkNet\n",
        "- YOLOv5\n",
        "\n",
        "SuperGradients provides ready-to-use dataloaders for these datasets. If you're interested in learning more about working with `COCOFormatDetectionDataset` and the more general `DetectionDataset` [check out the SuperGradients documentation on this topic](https://docs.deci.ai/super-gradients/docstring/training/datasets/#training.datasets.detection_datasets.coco_detection.COCODetectionDataset)\n",
        "\n",
        "You can learn more about working with SuperGradients datasets, dataloaders, and configuration files [here.](https://github.com/Deci-AI/super-gradients/blob/master/documentation/source/Data.md)\n",
        "\n",
        "SuperGradients supports a number of dataset formats, you can learn more about that [here.](https://github.com/Deci-AI/super-gradients/blob/master/documentation/source/ObjectDetection.md)\n",
        "\n",
        "For this example you'll use the the [U.S. Coins Dataset](https://universe.roboflow.com/atathamuscoinsdataset/u.s.-coins-dataset-a.tatham/dataset/5) from [RoboFlow](https://app.roboflow.com/login) with the dataset in YOLOv5 format.\n",
        "\n",
        "## Some datasets you might want to try:\n",
        " - [HuggingFace competition: Ship detection](https://huggingface.co/spaces/competitions/ship-detection)\n",
        "\n",
        "- [Aquarium dataset on RoboFlow](https://public.roboflow.com/object-detection/aquarium)\n",
        "\n",
        "- [Vehicles-OpenImages Dataset on RoboFlow](https://public.roboflow.com/object-detection/vehicles-openimages)\n",
        "\n",
        "- [Winegrape detection](https://github.com/thsant/wgisd)\n",
        "\n",
        "- [Low light object detection](https://github.com/cs-chan/Exclusively-Dark-Image-Dataset)\n",
        "\n",
        "- [Infrafred person detection](https://camel.ece.gatech.edu/)\n",
        "\n",
        "- [Pothole detection](https://www.kaggle.com/datasets/chitholian/annotated-potholes-dataset)\n",
        "\n",
        "- [100k Labeled Road Images | Day, Night](https://www.kaggle.com/datasets/solesensei/solesensei_bdd100k)\n",
        "\n",
        "- [Deep Fashion dataset](https://github.com/switchablenorms/DeepFashion2)\n",
        "\n",
        "- [Playing card detection](https://www.kaggle.com/datasets/luantm/playing-card)\n",
        "\n",
        "- [Anaomoly detection in videos](https://www.crcv.ucf.edu/projects/real-world/)\n",
        "\n",
        "- [Underwater fish recognition](https://www.kaggle.com/datasets/aalborguniversity/brackish-dataset)\n",
        "\n",
        "- [Document layout detection](https://www.primaresearch.org/datasets/Layout_Analysis)\n",
        "\n",
        "- [Trash Annotations in Context](http://tacodataset.org/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dASKjwC2vCuk"
      },
      "outputs": [],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"<your-roboflow-key-here>\")\n",
        "project = rf.workspace(\"atathamuscoinsdataset\").project(\"u.s.-coins-dataset-a.tatham\")\n",
        "dataset = project.version(5).download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oBojddp2dTY"
      },
      "source": [
        "Start by importing the required modules, which will help you create SuperGradients dataloaders.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6voUp-K2qHU"
      },
      "outputs": [],
      "source": [
        "from super_gradients.training import dataloaders\n",
        "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_train, coco_detection_yolo_format_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cru1AMcY5AU0"
      },
      "source": [
        "You'll need to load your dataset parameters into a dictionary, specifically defining:\n",
        "\n",
        "- path to the parent directory where your data lives\n",
        "- the child directory names for training, validation, and test (if you have testing set) images and labels\n",
        "- class names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nvw1wr95J8u"
      },
      "outputs": [],
      "source": [
        "dataset_params = {\n",
        "    'data_dir':'/content/U.S.-Coins-Dataset---A.Tatham-5',\n",
        "    'train_images_dir':'train/images',\n",
        "    'train_labels_dir':'train/labels',\n",
        "    'val_images_dir':'valid/images',\n",
        "    'val_labels_dir':'valid/labels',\n",
        "    'test_images_dir':'test/images',\n",
        "    'test_labels_dir':'test/labels',\n",
        "    'classes': ['Dime', 'Nickel', 'Penny', 'Quarter']\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgunnL1IIu4v"
      },
      "source": [
        "You pass the values for `dataset_params` into the `dataset_params` argument as shown below.\n",
        "\n",
        "You can also pass PyTorch DataLoaders arguments when instantiating your dataset. Here you'll set `batch_size=16` and `num_workers=2`.\n",
        "\n",
        "Repeat this for the validation and testing datasets, note that for training and testing data we use `coco_detection_yolo_format_val` to instantiate the dataloader.\n",
        "\n",
        "The dataloaders will print warnings when an annotation does not conform to the expected format. This particular dataset has many such annotations, thus the warnings will be muted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVYPTxP32pxF"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "train_data = coco_detection_yolo_format_train(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['train_images_dir'],\n",
        "        'labels_dir': dataset_params['train_labels_dir'],\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size':16,\n",
        "        'num_workers':2\n",
        "    }\n",
        ")\n",
        "\n",
        "val_data = coco_detection_yolo_format_val(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['val_images_dir'],\n",
        "        'labels_dir': dataset_params['val_labels_dir'],\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size':16,\n",
        "        'num_workers':2\n",
        "    }\n",
        ")\n",
        "\n",
        "test_data = coco_detection_yolo_format_val(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['test_images_dir'],\n",
        "        'labels_dir': dataset_params['test_labels_dir'],\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size':16,\n",
        "        'num_workers':2\n",
        "    }\n",
        ")\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyHwMpQSEQDG"
      },
      "source": [
        "### üßê Now inspect the dataset defined earlier.\n",
        "\n",
        "SuperGradients added `transforms` for you. You're free to experiment with these transformations as you please. You can also add in your own transformations from `torchvision.transforms` or a custom tranformaton."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.dataset.transforms"
      ],
      "metadata": {
        "id": "1Os3Wky5carW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can plot a batch of training data with their augmentations applied to see what they look like:"
      ],
      "metadata": {
        "id": "FlV3ZpE-b24i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.dataset.plot()"
      ],
      "metadata": {
        "id": "F-u0KiX9bk1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW4Qg5YuR0mD"
      },
      "source": [
        "# üë©üèΩ‚Äçü¶≥ Instantiating the model\n",
        "\n",
        "You saw how to instantiate the model for inference earlier.\n",
        "\n",
        "Below is how to instantiate the model for finetuning. Note you need to add the `num_classes` argument here.\n",
        "\n",
        "Note, for this tutorial you're using `yolo_nas_l`, but SuperGradients has two other flavors of YOLONAS available to you: `yolo_nas_s` and `yolo_nas_m`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iZihVp_dlwr"
      },
      "outputs": [],
      "source": [
        "from super_gradients.training import models\n",
        "model = models.get('yolo_nas_l',\n",
        "                   num_classes=len(dataset_params['classes']),\n",
        "                   pretrained_weights=\"coco\"\n",
        "                   )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTe5a7-7efZR"
      },
      "source": [
        "# üéõÔ∏è Training parameters\n",
        "\n",
        "You need to define the training parameters for your training run.\n",
        "\n",
        "Full details about the training parameters can be found [here](https://github.com/Deci-AI/super-gradients/blob/master/src/super_gradients/recipes/training_hyperparams/default_train_params.yaml).\n",
        "\n",
        "\n",
        "### üö® There are a few **mandatory** arguments that you must define for training params üö®\n",
        "\n",
        "- `max_epochs` - Max number of training epochs\n",
        "\n",
        "- `loss` - the loss function you want to use\n",
        "\n",
        "- `optimizer` - Optimizer you will be using\n",
        "\n",
        "- `train_metrics_list` - Metrics to log during training\n",
        "\n",
        "- `valid_metrics_list` - Metrics to log during training\n",
        "\n",
        "- `metric_to_watch` - metric which the model checkpoint will be saved according to\n",
        "\n",
        "You can choose from a variety of `optimizer`'s such as: Adam, AdamW, SGD, Lion, or RMSProps. If you choose to change the defualt parameters of these optimizrs you pass them into `optimizer_params`.\n",
        "\n",
        "\n",
        "### üßëüèæ‚Äçüî¨ Integrations with experiment monitoring tools\n",
        "\n",
        "SuperGradients has native integrations with Tensorboard, Weights and Biases, ClearML, and DagsHub.\n",
        "\n",
        "If your favorite monitoring tool is not supported by SuperGradients, you can simply implement a class inheriting from BaseSGLogger that you will then pass to the training parameters.\n",
        "\n",
        "If you're interested in monitoring experiments, you can learn more [in the docs](https://github.com/Deci-AI/super-gradients/blob/0fe46cd39572db34eb83d68e343fed97b8886fe9/documentation/source/experiment_monitoring.md).\n",
        "\n",
        "\n",
        "### ü™Ñ SuperGradients offers a number of training tricks right out of the box, such as:\n",
        "\n",
        "- Exponential moving average\n",
        "- Zero weight decay on bias and batch normalizatiom\n",
        "- Weight averaging\n",
        "- Batch accumulation\n",
        "- Precise BatchNorm\n",
        "\n",
        "You can read more details about these training tricks [here](https://heartbeat.comet.ml/a-better-way-to-train-your-neural-networks-813b60a5bd6a).\n",
        "\n",
        "If you're interested in building a using a custom metric with SuperGradients you can learn how [here](https://github.com/Deci-AI/super-gradients/blob/master/documentation/source/Metrics.md).\n",
        "\n",
        "Note you will have to set number of classes in two places below: `PPYoloELoss` and `DetectionMetrics_050`.\n",
        "\n",
        "You probably noticed that we make use of a post prediction callback, for details on how phase callbacks work in SuperGradients [check out our documentation](https://github.com/Deci-AI/super-gradients/blob/master/documentation/source/PhaseCallbacks.md).\n",
        "\n",
        "### üîï Note: I've enabled `silent_mode` so the notebook doesn't get longer than it already is. You should disable it so you can see what SuperGradients outputs during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TnXgisyefds"
      },
      "outputs": [],
      "source": [
        "from super_gradients.training.losses import PPYoloELoss\n",
        "from super_gradients.training.metrics import DetectionMetrics_050\n",
        "from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n",
        "\n",
        "train_params = {\n",
        "    # ENABLING SILENT MODE\n",
        "    'silent_mode': True,\n",
        "    \"average_best_models\":True,\n",
        "    \"warmup_mode\": \"linear_epoch_step\",\n",
        "    \"warmup_initial_lr\": 1e-6,\n",
        "    \"lr_warmup_epochs\": 3,\n",
        "    \"initial_lr\": 5e-4,\n",
        "    \"lr_mode\": \"cosine\",\n",
        "    \"cosine_final_lr_ratio\": 0.1,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"optimizer_params\": {\"weight_decay\": 0.0001},\n",
        "    \"zero_weight_decay_on_bias_and_bn\": True,\n",
        "    \"ema\": True,\n",
        "    \"ema_params\": {\"decay\": 0.9, \"decay_type\": \"threshold\"},\n",
        "    # ONLY TRAINING FOR 10 EPOCHS FOR THIS EXAMPLE NOTEBOOK\n",
        "    \"max_epochs\": 10,\n",
        "    \"mixed_precision\": True,\n",
        "    \"loss\": PPYoloELoss(\n",
        "        use_static_assigner=False,\n",
        "        # NOTE: num_classes needs to be defined here\n",
        "        num_classes=len(dataset_params['classes']),\n",
        "        reg_max=16\n",
        "    ),\n",
        "    \"valid_metrics_list\": [\n",
        "        DetectionMetrics_050(\n",
        "            score_thres=0.1,\n",
        "            top_k_predictions=300,\n",
        "            # NOTE: num_classes needs to be defined here\n",
        "            num_cls=len(dataset_params['classes']),\n",
        "            normalize_targets=True,\n",
        "            post_prediction_callback=PPYoloEPostPredictionCallback(\n",
        "                score_threshold=0.01,\n",
        "                nms_top_k=1000,\n",
        "                max_predictions=300,\n",
        "                nms_threshold=0.7\n",
        "            )\n",
        "        )\n",
        "    ],\n",
        "    \"metric_to_watch\": 'mAP@0.50'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8c38zUUefjo"
      },
      "source": [
        "# ü¶æ Training the model\n",
        "\n",
        "You've covered a lot of ground so far:\n",
        "\n",
        "‚úÖ Instantiated the trainer\n",
        "\n",
        "‚úÖ Defined your dataset parameters and dataloaders\n",
        "\n",
        "‚úÖ Instantiated a model\n",
        "\n",
        "‚úÖ Set up your training parameters\n",
        "\n",
        "### ‚è≥ Now, its time to train a model\n",
        "\n",
        "Training a model using a SuperGradients is done using the `trainer`.\n",
        "\n",
        "It's as easy as..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5sKiaH9efp-"
      },
      "outputs": [],
      "source": [
        "trainer.train(model=model,\n",
        "              training_params=train_params,\n",
        "              train_loader=train_data,\n",
        "              valid_loader=val_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sP59sDjefzK"
      },
      "source": [
        "# üèÜ Get the best trained model\n",
        "\n",
        "Now that training is complete, you need to get the best trained model.\n",
        "\n",
        "You used checkpoint averaging so the following code will use weights averaged across training runs.\n",
        "\n",
        "If you want to use the best weights, or weights from the last epoch you'd use one of the following in the code below:\n",
        "\n",
        "- best weights: `checkpoint_path = checkpoints/my_first_yolonas_run/ckpt_best.pth`\n",
        "\n",
        "- last weights: `checkpoint_path = checkpoints/my_first_yolonas_run/ckpt_latest.pth`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cXthCX2vgAC"
      },
      "outputs": [],
      "source": [
        "best_model = models.get('yolo_nas_l',\n",
        "                        num_classes=len(dataset_params['classes']),\n",
        "                        checkpoint_path=\"checkpoints/my_first_yolonas_run/average_model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gRaxH4dxJAx"
      },
      "source": [
        "# üßê Evaluating the best trained model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(model=best_model,\n",
        "            test_loader=test_data,\n",
        "            test_metrics_list=DetectionMetrics_050(score_thres=0.1,\n",
        "                                                   top_k_predictions=300,\n",
        "                                                   num_cls=len(dataset_params['classes']),\n",
        "                                                   normalize_targets=True,\n",
        "                                                   post_prediction_callback=PPYoloEPostPredictionCallback(score_threshold=0.01,\n",
        "                                                                                                          nms_top_k=1000,\n",
        "                                                                                                          max_predictions=300,\n",
        "                                                                                                          nms_threshold=0.7)\n",
        "                                                  ))"
      ],
      "metadata": {
        "id": "d112RM240zqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPdjT8Crw9UR"
      },
      "source": [
        "# üîÆ Predicting with the best model\n",
        "\n",
        "The next line will perform detection on the following image. Note, we didn't have a class for the half dollar coin. So it will likely get classified as something else.\n",
        "\n",
        "<img src='https://www.mynumi.net/media/catalog/product/cache/2/image/9df78eab33525d08d6e5fb8d27136e95/s/e/serietta_usa_2_1/www.mynumi.net-USASE5AD160-31.jpg'>\n",
        "\n",
        "The results aren't too bad after just a few epochs!\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EG3XCOYfw9d5"
      },
      "outputs": [],
      "source": [
        "img_url = 'https://www.mynumi.net/media/catalog/product/cache/2/image/9df78eab33525d08d6e5fb8d27136e95/s/e/serietta_usa_2_1/www.mynumi.net-USASE5AD160-31.jpg'\n",
        "best_model.predict(img_url).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-F_bRQ8w9lY"
      },
      "source": [
        "# Post training quantization (PTQ) and quantization aware training (QAT)\n",
        "\n",
        "SuperGradients offers PTQ and QAT out of the box. That's beyond the scope of this introductory tutorial. It is, in my opinion, a truly awesome feature.\n",
        "\n",
        "Not many training libaries offer this out of the box.  You can learn more about PTQ and QAT [here](https://github.com/Deci-AI/super-gradients/blob/c339e2619616878172c060e6491c8c2129ed3fd4/documentation/source/ptq_qat.md).\n",
        "\n",
        "An example specific to YOLONAS can be found [here](https://github.com/Deci-AI/super-gradients/blob/feature/SG-736_deci_yolo_rf100/documentation/source/qat_ptq_yolo_nas.md)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí´ I think you're ready to venture out on your own now!\n",
        "\n",
        "I've created a templated notebook for you [here](https://colab.research.google.com/drive/10N6NmSMCiRnFlKV9kaIS_z3pk0OI1xKC?usp=sharing).\n",
        "\n",
        "If you run into any issues, you know how to get a hold of me (contact info is at the top of the notebook).\n",
        "\n",
        "Cheers and I can't wait to see what you come up with!"
      ],
      "metadata": {
        "id": "p4kz-ucAPB3r"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}